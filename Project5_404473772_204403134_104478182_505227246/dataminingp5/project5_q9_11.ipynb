{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pytz\n",
    "import datetime\n",
    "import time\n",
    "import pandas as pd\n",
    "import winsound\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from math import sqrt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from tempfile import mkdtemp\n",
    "from shutil import rmtree\n",
    "from Project5_q6 import feature_extraction, min_max_timestamps\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.externals.joblib import Memory\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from pandas import ExcelWriter\n",
    "from pandas import DataFrame, read_csv\n",
    "import statsmodels.api as sm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pst_tz = pytz.timezone('America/Los_Angeles')\n",
    "\n",
    "\n",
    "frequency = 2500  # Set Frequency To 2500 Hertz\n",
    "duration = 1000  # Set Duration To 1000 ms == 1 second\n",
    "\n",
    "s = 'file_aggreg.txt'\n",
    "l = min_max_timestamps(s)\n",
    "\n",
    "beginstamp = l[0]\n",
    "endstamp = l[1]\n",
    "\n",
    "stamp1 = int(time.mktime(datetime.datetime(2015, 2, 1, 8, 0, 0, 0, pst_tz).timetuple()))\n",
    "stamp2 = int(time.mktime(datetime.datetime(2015, 2, 1, 20, 0, 0, 0, pst_tz).timetuple()))\n",
    "\n",
    "features = feature_extraction(beginstamp,endstamp,3600,s)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(10, 2), (10, 4), (10, 5), (10, 6), (10, 8), (10, 10), (10, 12), (10, 14), (10, 16), (10, 18), (10, 20), (20, 2), (20, 4), (20, 5), (20, 6), (20, 8), (20, 10), (20, 12), (20, 14), (20, 16), (20, 18), (20, 20), (30, 2), (30, 4), (30, 5), (30, 6), (30, 8), (30, 10), (30, 12), (30, 14), (30, 16), (30, 18), (30, 20), (40, 2), (40, 4), (40, 5), (40, 6), (40, 8), (40, 10), (40, 12), (40, 14), (40, 16), (40, 18), (40, 20), (50, 2), (50, 4), (50, 5), (50, 6), (50, 8), (50, 10), (50, 12), (50, 14), (50, 16), (50, 18), (50, 20), (60, 2), (60, 4), (60, 5), (60, 6), (60, 8), (60, 10), (60, 12), (60, 14), (60, 16), (60, 18), (60, 20), (70, 2), (70, 4), (70, 5), (70, 6), (70, 8), (70, 10), (70, 12), (70, 14), (70, 16), (70, 18), (70, 20), (80, 2), (80, 4), (80, 5), (80, 6), (80, 8), (80, 10), (80, 12), (80, 14), (80, 16), (80, 18), (80, 20), (90, 2), (90, 4), (90, 5), (90, 6), (90, 8), (90, 10), (90, 12), (90, 14), (90, 16), (90, 18), (90, 20), (100, 2), (100, 4), (100, 5), (100, 6), (100, 8), (100, 10), (100, 12), (100, 14), (100, 16), (100, 18), (100, 20), (200, 2), (200, 4), (200, 5), (200, 6), (200, 8), (200, 10), (200, 12), (200, 14), (200, 16), (200, 18), (200, 20), (500, 2), (500, 4), (500, 5), (500, 6), (500, 8), (500, 10), (500, 12), (500, 14), (500, 16), (500, 18), (500, 20)]\n",
      "\n",
      "132\n"
     ]
    }
   ],
   "source": [
    "x = [10,20,30,40,50,60,70,80,90,100,200,500]\n",
    "y = [2,4,5,6,8,10,12,14,16,18,20]\n",
    "num = 0\n",
    "my_tuples = []\n",
    "for i in x:\n",
    "    for j in y:\n",
    "        my_tuples.append((i,j))\n",
    "        num+=1\n",
    "print(my_tuples)\n",
    "print()\n",
    "print(num)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 132 candidates, totalling 660 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:    6.7s\n",
      "[Parallel(n_jobs=-1)]: Done 349 tasks      | elapsed:   13.3s\n",
      "[Parallel(n_jobs=-1)]: Done 632 tasks      | elapsed:   26.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hidden_layer_sizes': (70, 4)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 660 out of 660 | elapsed:   29.6s finished\n",
      "C:\\Users\\TEDDY\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\TEDDY\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\TEDDY\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\TEDDY\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split3_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\TEDDY\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split4_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\TEDDY\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\TEDDY\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "'hidden_layer_sizes': my_tuples\n",
    "}\n",
    "mlpr = MLPRegressor()\n",
    "grid_search = GridSearchCV( estimator = mlpr, param_grid = param_grid,\n",
    "                            cv=KFold(5, shuffle=True), n_jobs=-1,verbose = 2,scoring='neg_mean_squared_error')\n",
    "\n",
    "dk1 = features.values\n",
    "\n",
    "\n",
    "\n",
    "grid_search.fit(dk1[:,:-1], dk1[:,-1])\n",
    "\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "df = pd.DataFrame(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter('q11.xlsx', engine='xlsxwriter')\n",
    "df.to_excel(writer, sheet_name='Sheet1')\n",
    "writer.save()\n",
    "winsound.Beep(frequency, duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(dk1)\n",
    "scaled_donna_ft = scaler.transform(dk1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 132 candidates, totalling 660 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:    9.3s\n",
      "[Parallel(n_jobs=-1)]: Done 349 tasks      | elapsed:   23.2s\n",
      "[Parallel(n_jobs=-1)]: Done 632 tasks      | elapsed:   58.3s\n",
      "[Parallel(n_jobs=-1)]: Done 660 out of 660 | elapsed:  1.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hidden_layer_sizes': (500, 16)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TEDDY\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\TEDDY\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\TEDDY\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\TEDDY\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\TEDDY\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split3_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\TEDDY\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split4_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\TEDDY\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\TEDDY\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "grid_search.fit(scaled_donna_ft[:,:-1], dk1[:,-1])\n",
    "\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "dscaled = pd.DataFrame(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter('q12_targetunscale.xlsx', engine='xlsxwriter')\n",
    "dscaled.to_excel(writer, sheet_name='Sheet1')\n",
    "writer.save()\n",
    "winsound.Beep(frequency, duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################  question 9 ################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "datanum = features.values\n",
    "X = datanum[:,:-1]\n",
    "y = datanum[:, -1]\n",
    "\n",
    "X2 = sm.add_constant(X)\n",
    "est = sm.OLS(y, X2)\n",
    "est2 = est.fit()\n",
    "ypred = est2.predict(X2)\n",
    "olserror = (mean_squared_error(y, ypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101811465.79765353\n"
     ]
    }
   ],
   "source": [
    "print(olserror)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.872\n",
      "Model:                            OLS   Adj. R-squared:                  0.871\n",
      "Method:                 Least Squares   F-statistic:                     791.0\n",
      "Date:                Sat, 23 Mar 2019   Prob (F-statistic):          5.38e-256\n",
      "Time:                        19:38:40   Log-Likelihood:                -6223.4\n",
      "No. Observations:                 585   AIC:                         1.246e+04\n",
      "Df Residuals:                     579   BIC:                         1.248e+04\n",
      "Df Model:                           5                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const       -701.2521    434.758     -1.613      0.107   -1555.146     152.642\n",
      "x1            15.1063      1.101     13.727      0.000      12.945      17.268\n",
      "x2            -0.3325      0.084     -3.940      0.000      -0.498      -0.167\n",
      "x3             0.0559      0.004     13.212      0.000       0.048       0.064\n",
      "x4            -0.0003   3.65e-05     -8.927      0.000      -0.000      -0.000\n",
      "x5            -3.3039      0.270    -12.217      0.000      -3.835      -2.773\n",
      "==============================================================================\n",
      "Omnibus:                      991.383   Durbin-Watson:                   2.100\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           728004.449\n",
      "Skew:                          10.145   Prob(JB):                         0.00\n",
      "Kurtosis:                     174.625   Cond. No.                     2.47e+08\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 2.47e+08. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "print(est2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
