{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pytz\n",
    "import datetime\n",
    "import time\n",
    "import winsound\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from math import sqrt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import KFold\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pst_tz = pytz.timezone('America/Los_Angeles')\n",
    "\n",
    "def min_max_timestamps(s):\n",
    "    mincit = 10e9\n",
    "    maxcit = -1\n",
    "\n",
    "    with open(s, encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            json_object = json.loads(line)\n",
    "            if json_object['citation_date'] < mincit:\n",
    "                mincit = json_object['citation_date']\n",
    "            if json_object['citation_date'] > maxcit:\n",
    "                maxcit = json_object['citation_date']\n",
    "    return [mincit,maxcit]\n",
    "\n",
    "\n",
    "def feature_extraction(beginstamp, endstamp, window,s):\n",
    "    #############  Preprocessing #############\n",
    "    # if beginstamp % window == 0:\n",
    "    #     beginstamp = beginstamp\n",
    "    # else:\n",
    "    #     beginstamp -= beginstamp % window\n",
    "    #     beginstamp = beginstamp + window\n",
    "    beginstamp -= beginstamp % window\n",
    "\n",
    "    endstamp -= endstamp % window\n",
    "    #########################################\n",
    "    number_of_tweets = [0 for stamp in range(beginstamp, endstamp, window)]\n",
    "    number_of_retweets = [0 for stamp in range(beginstamp, endstamp, window)]\n",
    "    s_number_of_followers = [0 for stamp in range(beginstamp, endstamp, window)]\n",
    "    max_of_followers = [0 for stamp in range(beginstamp, endstamp, window)]\n",
    "    time_of_day = [0 for stamp in range(beginstamp, endstamp, window)]\n",
    "    listed_count = [0 for stamp in range(beginstamp, endstamp, window)]\n",
    "    s_foll_of_orig_auth = [0 for stamp in range(beginstamp, endstamp, window)]\n",
    "    ranking_score = [0 for stamp in range(beginstamp, endstamp, window)]\n",
    "    num = 0\n",
    "    target = [0 for stamp in range(beginstamp, endstamp, window)]\n",
    "\n",
    "    for idx, stamp in enumerate(range(beginstamp, endstamp, window)):\n",
    "        time_of_day[idx] = datetime.datetime.fromtimestamp(stamp, pst_tz).hour\n",
    "\n",
    "    limit = int((endstamp - beginstamp) / window)\n",
    "\n",
    "    with open(s, encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            # print(line)\n",
    "            json_object = json.loads(line)\n",
    "            stamp = json_object['citation_date']\n",
    "            stamp -= stamp % window\n",
    "            idx = int((stamp - beginstamp) / window)\n",
    "\n",
    "            if idx < limit and idx >=0:\n",
    "\n",
    "                number_of_tweets[idx] += 1\n",
    "                num +=1\n",
    "                number_of_retweets[idx] += json_object['metrics']['citations']['total']\n",
    "                s_number_of_followers[idx] += json_object['author']['followers']\n",
    "                max_of_followers[idx] = max(max_of_followers[idx], json_object['author']['followers'])\n",
    "                hehe = json_object['tweet']['user']['listed_count']\n",
    "                listed_count[idx] += hehe if hehe != None else 0\n",
    "                s_foll_of_orig_auth[idx] += json_object['original_author']['followers']\n",
    "                ranking_score[idx] += json_object['metrics']['ranking_score']\n",
    "            if idx > 0 and idx <=limit:\n",
    "\n",
    "                target[idx - 1] += 1\n",
    "    # print(s)\n",
    "    # print(num)\n",
    "    feature_target = pd.DataFrame(\n",
    "        {'number_of_tweets': number_of_tweets,\n",
    "         'number_of_retweets': number_of_retweets,\n",
    "\n",
    "         'listed_count': listed_count,\n",
    "         's_foll_of_orig_auth': s_foll_of_orig_auth,\n",
    "         'ranking_score': ranking_score,\n",
    "         'target': target\n",
    "         })\n",
    "    return feature_target\n",
    "\n",
    "\n",
    "\n",
    "def lin_regress_r(datum,testname,testwindow):\n",
    "\n",
    "\n",
    "    reg_fin = LinearRegression().fit(datum[:,:-1], datum[:,-1])\n",
    "    pred = reg_fin.predict(datum[:,:-1])\n",
    "    rmse_trn = (mean_squared_error(datum[:, -1], pred))\n",
    "\n",
    "\n",
    "    ################################  testing ##########################################################\n",
    "\n",
    "    l = min_max_timestamps(testname)\n",
    "\n",
    "    beginstamptest = l[0]\n",
    "    endstamptest = l[1]\n",
    "    testfeatures = feature_extraction(beginstamptest,endstamptest,testwindow,testname)\n",
    "    testdata = testfeatures.values\n",
    "    testpred = reg_fin.predict(testdata[:, :-1])\n",
    "\n",
    "  \n",
    "    actual = testdata[:, -1]\n",
    "  \n",
    "    testrmse = (mean_squared_error(testdata[:, -1], testpred))\n",
    "    for i in range(5):\n",
    "        print('%.2f'%actual[i],'&','%.2f'%testpred[i],'\\\\\\ \\hline')\n",
    "        \n",
    "    print()\n",
    "    print(testname,'&',testrmse,'\\\\\\ \\hline')\n",
    "    print('-'*35)\n",
    "\n",
    "    return [testrmse]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#names = [\"tweets_#gohawks.txt\", \"tweets_#gopatriots.txt\",\"tweets_#nfl.txt\", \"tweets_#patriots.txt\", \"tweets_#sb49.txt\", \"tweets_#superbowl.txt\"]\n",
    "names = ['file_aggreg.txt']\n",
    "frequency = 2500  # Set Frequency To 2500 Hertz\n",
    "duration = 2000  # Set Duration To 1000 ms == 1 second\n",
    "testnames = ['sample0_period1.txt','sample0_period2.txt','sample0_period3.txt','sample1_period1.txt','sample1_period2.txt','sample1_period3.txt','sample2_period1.txt','sample2_period2.txt','sample2_period3.txt']\n",
    "# s = 'ECE219_tweet_data/tweets_#gopatriots.txt'\n",
    "# s_write = 'tweets_#gopatriots.xlsx'\n",
    "for s in names:\n",
    "    l = min_max_timestamps(s)\n",
    "\n",
    "    beginstamp = l[0]\n",
    "    endstamp = l[1]\n",
    "    \n",
    "    stamp1 = int(time.mktime(datetime.datetime(2015, 2, 1, 8, 0, 0, 0, pst_tz).timetuple()))\n",
    "    stamp2 = int(time.mktime(datetime.datetime(2015, 2, 1, 20, 0, 0, 0, pst_tz).timetuple()))\n",
    "    \n",
    "    feature1 = feature_extraction(beginstamp,stamp1,3600,s)\n",
    "    feature2 = feature_extraction(stamp1,stamp2,300,s)\n",
    "    feature3 = feature_extraction(stamp2,endstamp,3600,s)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample0_period1.txt\n",
      "79.00 & 551.52 \\\\ \\hline\n",
      "94.00 & 601.67 \\\\ \\hline\n",
      "101.00 & 580.04 \\\\ \\hline\n",
      "122.00 & 665.35 \\\\ \\hline\n",
      "120.00 & 573.10 \\\\ \\hline\n",
      "\n",
      "sample0_period1.txt & 242201.8052171222 \\\\ \\hline\n",
      "-----------------------------------\n",
      "\n",
      "sample0_period2.txt\n",
      "3834.00 & 4304.73 \\\\ \\hline\n",
      "2258.00 & 4509.67 \\\\ \\hline\n",
      "1455.00 & 2962.63 \\\\ \\hline\n",
      "1235.00 & 1942.59 \\\\ \\hline\n",
      "1123.00 & 1956.05 \\\\ \\hline\n",
      "\n",
      "sample0_period2.txt & 1751840.8720342466 \\\\ \\hline\n",
      "-----------------------------------\n",
      "\n",
      "sample0_period3.txt\n",
      "48.00 & 393.50 \\\\ \\hline\n",
      "94.00 & 352.80 \\\\ \\hline\n",
      "45.00 & 382.84 \\\\ \\hline\n",
      "77.00 & 369.21 \\\\ \\hline\n",
      "87.00 & 367.96 \\\\ \\hline\n",
      "\n",
      "sample0_period3.txt & 92962.60184462288 \\\\ \\hline\n",
      "-----------------------------------\n",
      "\n",
      "sample1_period1.txt\n",
      "180.00 & 613.24 \\\\ \\hline\n",
      "202.00 & 566.80 \\\\ \\hline\n",
      "294.00 & 614.48 \\\\ \\hline\n",
      "555.00 & 726.85 \\\\ \\hline\n",
      "846.00 & 882.50 \\\\ \\hline\n",
      "\n",
      "sample1_period1.txt & 90869.38415277826 \\\\ \\hline\n",
      "-----------------------------------\n",
      "\n",
      "sample1_period2.txt\n",
      "995.00 & 1692.14 \\\\ \\hline\n",
      "870.00 & 1767.45 \\\\ \\hline\n",
      "960.00 & 1582.29 \\\\ \\hline\n",
      "861.00 & 2011.24 \\\\ \\hline\n",
      "903.00 & 1595.18 \\\\ \\hline\n",
      "\n",
      "sample1_period2.txt & 696164.5677741631 \\\\ \\hline\n",
      "-----------------------------------\n",
      "\n",
      "sample1_period3.txt\n",
      "87.00 & 346.10 \\\\ \\hline\n",
      "43.00 & 390.89 \\\\ \\hline\n",
      "27.00 & 339.82 \\\\ \\hline\n",
      "44.00 & 337.82 \\\\ \\hline\n",
      "46.00 & 362.84 \\\\ \\hline\n",
      "\n",
      "sample1_period3.txt & 94547.67851794083 \\\\ \\hline\n",
      "-----------------------------------\n",
      "\n",
      "sample2_period1.txt\n",
      "141.00 & 748.46 \\\\ \\hline\n",
      "102.00 & 600.28 \\\\ \\hline\n",
      "144.00 & 525.51 \\\\ \\hline\n",
      "104.00 & 560.27 \\\\ \\hline\n",
      "61.00 & 616.00 \\\\ \\hline\n",
      "\n",
      "sample2_period1.txt & 255808.28140868936 \\\\ \\hline\n",
      "-----------------------------------\n",
      "\n",
      "sample2_period2.txt\n",
      "19.00 & 858.47 \\\\ \\hline\n",
      "25.00 & 872.71 \\\\ \\hline\n",
      "27.00 & 879.22 \\\\ \\hline\n",
      "29.00 & 913.81 \\\\ \\hline\n",
      "28.00 & 874.08 \\\\ \\hline\n",
      "\n",
      "sample2_period2.txt & 729667.5109910346 \\\\ \\hline\n",
      "-----------------------------------\n",
      "\n",
      "sample2_period3.txt\n",
      "90.00 & 390.78 \\\\ \\hline\n",
      "40.00 & 405.03 \\\\ \\hline\n",
      "58.00 & 376.59 \\\\ \\hline\n",
      "87.00 & 346.10 \\\\ \\hline\n",
      "43.00 & 390.89 \\\\ \\hline\n",
      "\n",
      "sample2_period3.txt & 102675.57098636948 \\\\ \\hline\n",
      "-----------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "    name = ['MSE score','R-squared score','Train MSE','Test MSE']\n",
    "    for i in range(3):\n",
    "        dk1 = feature1.values\n",
    "        print(testnames[i*3+0])\n",
    "        win1 = lin_regress_r(dk1,testnames[i*3+0],3600)\n",
    "        print()\n",
    "        dk2 = feature2.values\n",
    "        print(testnames[i*3+1])\n",
    "        win2 = lin_regress_r(dk2,testnames[i*3+1],300)\n",
    "        print()\n",
    "\n",
    "        dk3 = feature3.values\n",
    "        print(testnames[i*3+2])\n",
    "        win3 = lin_regress_r(dk3,testnames[i*3+2],3600)\n",
    "        print()\n",
    "\n",
    "    winsound.Beep(frequency, duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
